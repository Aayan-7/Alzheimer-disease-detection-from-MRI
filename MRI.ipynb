{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0ee02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = \"D:\\\\MRI\\\\OAS2_0002_MR1\\\\1\\\\123127134\\\\mpr-1.nifti.img\"\n",
    "\n",
    "\"D:\\MRI - Copy\\OAS2_0002_MR1\\1\\123127134\\mpr-1.nifti.img\"# Load the NIfTI image\n",
    "image = nib.load(file_path)\n",
    "                                \n",
    "            \n",
    "# Get the image data\n",
    "image_data = image.get_fdata()\n",
    "# Display the image\n",
    "plt.imshow(image_data[:, :, 70], cmap=None)  # Display a middle slice (in this case, slice 64)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e024e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ants\n",
    "\n",
    "image_path = \"D:\\\\biasmpr-1.nifti.img\"\n",
    "\n",
    "image = ants.image_read(image_path)\n",
    "\n",
    "resampled_image = ants.resample_image(image, (1, 1, 1))\n",
    "\n",
    "resampled_image_path = \"D:\\\\resampledmpr-1.nifti.img\"\n",
    "ants.image_write(resampled_image, resampled_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ants\n",
    "\n",
    "image_path = \"D:\\\\resampledmpr-1.nifti.img\"\n",
    "\n",
    "image = ants.image_read(image_path)\n",
    "\n",
    "denoised_image = ants.denoise_image(image, noise_model='Gaussian')\n",
    "\n",
    "denoised_image_path = \"D:\\\\deionisedmpr-1.nifti.img\"\n",
    "ants.image_write(denoised_image, denoised_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c832bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ants\n",
    "\n",
    "image_path = \"D:\\\\deionisedmpr-1.nifti.img\"\n",
    "\n",
    "image = ants.image_read(image_path)\n",
    "\n",
    "normalized_image = ants.iMath(image, 'Normalize')\n",
    "\n",
    "normalized_image_path = \"D:\\\\normaliseddmpr-1.nifti.img\"\n",
    "ants.image_write(normalized_image, normalized_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05beb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "image_path = \"D:\\\\MRI - Copy\\\\OAS2_0001_MR2\\\\1\\\\123127131\\\\mpr-1.nifti.img\"\n",
    "image = nib.load(image_path)\n",
    "image_data = image.get_fdata()\n",
    "# Display a single slice\n",
    "slice_index = 50  # Specify the desired slice index\n",
    "plt.imshow(image_data[:, :, slice_index], cmap=None)\n",
    "plt.title(\"MRI Slice\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "from skimage.draw import polygon\n",
    "\n",
    "# Specify the coordinates of the ROI\n",
    "x1, y1 = 10, 60  # Top-left corner\n",
    "x2, y2 = 210, 115  # Top-right corner\n",
    "x3, y3 = 180, 180  # Bottom-right corner\n",
    "x4, y4 = 40, 180  # Bottom-left corner\n",
    "x5, y5 = 20, 145\n",
    "# Create a binary mask for the rectangular ROI\n",
    "roi_mask = np.zeros_like(image_data)\n",
    "rr, cc = polygon([x1, x2, x3, x4,x5], [y1, y2, y3, y4,y5])\n",
    "roi_mask[rr, cc, slice_index] = 1\n",
    "\n",
    "# Apply the ROI mask to the MRI slice\n",
    "roi_slice = image_data[:, :, slice_index] * roi_mask[:, :, slice_index]\n",
    "\n",
    "# Display the ROI slice\n",
    "plt.imshow(roi_slice, cmap=None)\n",
    "plt.title(\"ROI Slice\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eafb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Load the .nifti file\n",
    "nifti_img = nib.load(\"D:\\\\MRI\\\\OAS2_0001_MR2\\\\1\\\\123127131\\\\mpr-1.nifti.img\")\n",
    "\n",
    "# Access the image data\n",
    "image_data = nifti_img.get_fdata()\n",
    "\n",
    "# Print the image shape\n",
    "print('Image shape:', image_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03956d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the voxel dimensions\n",
    "voxel_dims = nifti_img.header['pixdim'][1:4]\n",
    "print('Voxel dimensions:', voxel_dims)\n",
    "\n",
    "# Access the image intensity values\n",
    "intensity_values = image_data.flatten()\n",
    "print('Min intensity:', intensity_values.min())\n",
    "print('Max intensity:', intensity_values.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc977d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn import image\n",
    "\n",
    "# Resample the image to isotropic voxel dimensions of 1mm\n",
    "resampled_img = image.resample_img(nifti_img, target_affine=np.array([(1, 0, 0, 0),\n",
    "                                                                      (0, 1, 0, 0),\n",
    "                                                                      (0, 0, 1, 0),\n",
    "                                                                      (0, 0, 0, 1)]),\n",
    "                                   target_shape=(256, 256, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the intensity values to the range [0, 1]\n",
    "normalized_data = (image_data - np.min(image_data)) / (np.max(image_data) - np.min(image_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70334bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Apply Gaussian filtering with a sigma value of 1\n",
    "denoised_data = gaussian_filter(image_data, sigma=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fdd6bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display a slice of the image\n",
    "slice_index = 100\n",
    "plt.imshow(image_data[:, :, slice_index], cmap=None)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.ants.segmentation import N4BiasFieldCorrection\n",
    "from dipy.segment.tissue import TissueClassifierHMRF\n",
    "from dipy.io.image import load_nifti_data\n",
    "from __future__ import print_function\n",
    "from deepbrain import Extractor\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "import numpy as np\n",
    "  \n",
    "class Preprocess:\n",
    "\n",
    "  def __init__(self):\n",
    "    \n",
    "    \n",
    "    print('Start preprocessing....')\n",
    "\n",
    "  def strip_the_skull(self,src_path,dst_path):\n",
    "  \n",
    "    img = nib.load(src_path)\n",
    "    affine = img.affine\n",
    "    img = img.get_fdata()\n",
    "    ext = Extractor()\n",
    "    prob = ext.run(img)\n",
    "    mask = prob > 0.5\n",
    "    brain = img[:]\n",
    "    brain[~mask] = 0\n",
    "    brain = nib.Nifti1Image(brain, affine)\n",
    "    nib.save(brain, dst_path)\n",
    "\n",
    "    \n",
    "  def get_noiseless_image(self,src_path,dst_path):\n",
    "  \n",
    "    try:\n",
    "      inputImage = sitk.ReadImage(src_path)\n",
    "      img_data=sitk.Cast(inputImage,sitk.sitkFloat32) \n",
    "      img_mask=sitk.BinaryNot(sitk.BinaryThreshold(img_data, 0, 0))\n",
    "      corrected_img = sitk.N4BiasFieldCorrection(inputImage, img_mask)\n",
    "      sitk.WriteImage(corrected_img, dst_path)\n",
    "      print('Succesfully performed N4 Bias Correction')\n",
    "    \n",
    "    except RuntimeError:\n",
    "      #Runs if any stmts of Bias Correction fails\n",
    "      print('Failed on :' + src_path)  \n",
    "  \n",
    "  def do_segmentation(self,src_path,dst_path):\n",
    "   \n",
    "    #To get only the image data array\n",
    "    t1 = load_nifti_data(src_path)\n",
    "    print('t1.shape (%d, %d, %d)' % t1.shape)\n",
    "    #To load the entire nifti file\n",
    "    t2 = nib.load(src_path)\n",
    "    nclass = 3\n",
    "    beta = 0.1\n",
    "    t0 = time.time()\n",
    "    hmrf = TissueClassifierHMRF()\n",
    "    #Perform segmentation\n",
    "    initial_segmentation, final_segmentation, PVE = hmrf.classify(t1, nclass, beta)\n",
    "    t1 = time.time()\n",
    "    total_time = t1-t0\n",
    "    print('Total time:' + str(total_time))\n",
    "    print(final_segmentation.shape)\n",
    "    brain = nib.Nifti1Image(final_segmentation,t2.affine)\n",
    "    print('Segmentation performed successfully')\n",
    "    nib.save(brain, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbfe1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the root directory containing the image folders\n",
    "root_dir = 'D:\\\\MRI - copy\\\\'\n",
    "input_image = Preprocess()\n",
    "# Iterate over the folders\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    \n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over the files in the folder\n",
    "        for folder1 in os.listdir(folder_path):\n",
    "            folder1_path = os.path.join(folder_path, folder1)\n",
    "            path_to_store_stripped_skull=os.path.join(folder1_path,\"sssmpr.nifti.img\")\n",
    "            path_to_store_segmented_img=os.path.join(folder1_path,\"segmentmpr.nifti.img\")\n",
    "            \n",
    "            if os.path.isdir(folder1_path):\n",
    "                # Iterate over the files in the folder\n",
    "                for folder2 in os.listdir(folder1_path):\n",
    "                    folder2_path = os.path.join(folder1_path, folder2)\n",
    "                    \n",
    "                    if os.path.isdir(folder2_path):\n",
    "                        \n",
    "                        # Iterate over the files in the folder\n",
    "                        for folder3 in os.listdir(folder2_path):\n",
    "                            folder3_path = os.path.join(folder2_path, folder3)\n",
    "                            \n",
    "                            \n",
    "                            # Check if the item is a file\n",
    "                            if folder3_path.endswith('mpr-1.nifti.img'):\n",
    "                                input_image.strip_the_skull(folder3_path,path_to_store_stripped_skull)\n",
    "                                input_image.do_segmentation(path_to_store_stripped_skull,path_to_store_segmented_img)\n",
    "\n",
    "                                # Get the image data\n",
    "                                #image_data = image.get_fdata()\n",
    "\n",
    "                                # Display the image\n",
    "                                #plt.imshow(image_data[:, :, 64], cmap=None)  # Display a middle slice (in this case, slice 64)\n",
    "                                #plt.axis('off')\n",
    "                                #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dae8f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.color import rgb2gray\n",
    "df=pd.DataFrame(columns=['contrast','dissimilarity','homogeneity','energy','correlation'])\n",
    "df\n",
    "\n",
    "root_dir = 'D:\\\\MRI - copy\\\\'\n",
    "\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    \n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over the files in the folder\n",
    "        for folder1 in os.listdir(folder_path):\n",
    "            folder1_path = os.path.join(folder_path, folder1)\n",
    "            \n",
    "            if os.path.isdir(folder1_path):\n",
    "                        \n",
    "                # Iterate over the files in the folder\n",
    "                for folder2 in os.listdir(folder1_path):\n",
    "                    folder2_path = os.path.join(folder1_path, folder2)\n",
    "                            \n",
    "                            \n",
    "                        # Check if the item is a file\n",
    "                    if folder2_path.endswith('segmentmpr.nifti.img'):\n",
    "                        print(folder2_path)\n",
    "                        image = nib.load(folder2_path)\n",
    "                        segmented_image_data = image.get_fdata()\n",
    "\n",
    "                        # Check the dimensions of the segmented image\n",
    "                        num_slices = segmented_image_data.shape[2]\n",
    "                        print(\"Number of slices:\", num_slices)\n",
    "\n",
    "                        # Select a slice for processing (e.g., slice_index = 0)\n",
    "                        slice_index = 0\n",
    "                        slice_image = segmented_image_data[:, :, slice_index]\n",
    "\n",
    "                        gray_image = slice_image.squeeze()\n",
    "                        \n",
    "                        gray_image = np.uint8(gray_image)\n",
    "\n",
    "                        # Define the distances and angles for GLCM calculation\n",
    "                        distances = [1]  # Distance between pixels\n",
    "                        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Angles for texture analysis\n",
    "\n",
    "                        # Compute the GLCM matrix\n",
    "                        glcm = greycomatrix(gray_image, distances, angles, symmetric=True, normed=True)\n",
    "\n",
    "                        # Calculate texture features from the GLCM matrix\n",
    "                        contrast = greycoprops(glcm, 'contrast')\n",
    "                        dissimilarity = greycoprops(glcm, 'dissimilarity')\n",
    "                        homogeneity = greycoprops(glcm, 'homogeneity')\n",
    "                        energy = greycoprops(glcm, 'energy')\n",
    "                        correlation = greycoprops(glcm, 'correlation')\n",
    "                        \n",
    "                        print(\"Contrast:\", contrast)\n",
    "                        print(\"Dissimilarity:\", dissimilarity)\n",
    "                        print(\"Homogeneity:\", homogeneity)\n",
    "                        print(\"Energy:\", energy)\n",
    "                        print(\"Correlation:\", correlation)\n",
    "                        \n",
    "                        df.loc[len(df.index)] = [contrast,dissimilarity,homogeneity,energy,correlation]\n",
    "                            \n",
    "df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"D:\\\\Datasets\\\\oasis_longitudinal_demographics.xlsx\")\n",
    "df1=df1[['MRI ID','Group']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.join(df)\n",
    "df2=df2.set_index('MRI ID')\n",
    "df2= df2[df2['Group'] != 'Converted']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df2.drop('Group',axis=1).columns:\n",
    "    df2[column] = df2[column].apply(lambda x: np.array(x).flatten())\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b9986",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in df2.drop('Group', axis=1).columns:\n",
    "    for i in range(len(df[column][0])):\n",
    "        df2[f'{column}_element{i+1}'] = df2[column].apply(lambda x: x[i])\n",
    "        df2[f'{column}_element{i+2}'] = df2[column].apply(lambda x: x[i+1])\n",
    "        df2[f'{column}_element{i+3}'] = df2[column].apply(lambda x: x[i+2])\n",
    "        df2[f'{column}_element{i+4}'] = df2[column].apply(lambda x: x[i+3])\n",
    "        \n",
    "# Drop the original feature columns if desired\n",
    "df2 = df2.drop(['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation'], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19eab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['contrast'] = df2[['contrast_element1','contrast_element2','contrast_element3','contrast_element4']].mean(axis=1)\n",
    "df2['dissimilarity'] = df2[['dissimilarity_element1','dissimilarity_element2','dissimilarity_element3','dissimilarity_element4']].mean(axis=1)\n",
    "df2['homogeneity'] = df2[['homogeneity_element1','homogeneity_element2','homogeneity_element3','homogeneity_element4']].mean(axis=1)\n",
    "df2['energy'] = df2[['energy_element1','energy_element2','energy_element3','energy_element4']].mean(axis=1)\n",
    "df2['correlation'] = df2[['correlation_element1','correlation_element2','correlation_element3','correlation_element4']].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[['Group','contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(['dissimilarity','contrast'],axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b68244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6c09a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Prepare the Data\n",
    "X = df2.drop(['Group','contrast'],axis=1)  # Numerical features\n",
    "y = df2['Group']  # Textual class label\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# Step 2: Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3,random_state=42)\n",
    "\n",
    "# Encode the target variable\n",
    "\n",
    "\n",
    "# Step 3: Preprocess the Data (if needed)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Build the Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Step 5: Compile the Model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the Model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=15, batch_size=8, verbose=1, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Step 7: Make Predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.where(y_pred_prob >= 0.5, 1, 0)\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(X_train_scaled)\n",
    "y_pred = np.where(y_pred_prob >= 0.5, 1, 0)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Access the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True) # without custom font\n",
    "from PIL import ImageFont\n",
    "font = ImageFont.truetype(\"arial.ttf\", 12)\n",
    "visualkeras.layered_view(model, legend=True, font=font) # selected font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
